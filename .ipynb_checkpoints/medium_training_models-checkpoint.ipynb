{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers.charting_tools import Charting\n",
    "from helpers.data_processing import add_ti\n",
    "from BookWorm import BookWorm, BinanceWrapper\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "worm = BookWorm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "candles = worm.historical_candles(start_time='January 1 2019', end_time='February 1 2019', api_wrapper=BinanceWrapper('5lJ0uGit9PuUxHka3hBWhPmsi7dWyxEwvEntUZFKmm0xfNz3VjHWi5WSr5W1VBJV',\n",
    "                                                      'BFWVs8ko7Cd4sjdQ9amGJTnToGWy9TbQWIjeorSCj23FGiwFaknzkgLPcrgWrxsw'), \n",
    "                  symbol='ETHBTC', interval='1m')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter/Projects/FALKOR/helpers/data_processing.py:71: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[label] = ti_dict[label]\n"
     ]
    }
   ],
   "source": [
    "candles = add_ti(candles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_candles(df, num_rows=30, step=10):\n",
    "    \"\"\"Split a DataFrame of candlestick data into a list of smaller DataFrames each with num_rows rows\"\"\"\n",
    "    \n",
    "    slices = []\n",
    "    \n",
    "    for row_i in range(0, df.shape[0] - num_rows, step):\n",
    "        small_df = df.iloc[row_i:row_i+num_rows, :]\n",
    "        slices.append(small_df)\n",
    "        \n",
    "    return slices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def price_returns(df, num_rows=30, num_into_fut=5, step=10):\n",
    "    labels = []\n",
    "    \n",
    "    for row_i in range(0, df.shape[0] - num_rows - num_into_fut, step):\n",
    "        # skip all iterations while row_i < num_rows since nothing yet to create a label for\n",
    "        if row_i <= num_rows: continue\n",
    "        \n",
    "        vf, vi = df['close'][row_i+num_into_fut], df['close'][row_i]\n",
    "        price_return = (vf - vi) / vi\n",
    "        labels.append(price_return)\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4455"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# split candles into 30 period and a label\n",
    "candles_sliced = split_candles(candles)\n",
    "labels_candles_sliced = price_returns(candles)\n",
    "# we need to remove candle slices without a label from candles_sliced\n",
    "candles_sliced = candles_sliced[len(candles_sliced)-len(labels_candles_sliced):]\n",
    "\n",
    "assert len(candles_sliced) == len(labels_candles_sliced)\n",
    "len(candles_sliced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_charts(candles_sliced, save_path):\n",
    "    \"\"\"Create a chart image for each in sliced_candles and return a list of paths to those images\"\"\"\n",
    "    from tqdm import tqdm_notebook as tqdm\n",
    "    import warnings\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    \n",
    "    i = 0\n",
    "    paths_to_images = []\n",
    "    for small_df in tqdm(candles_sliced):\n",
    "        chart = Charting(small_df, 'time', 'close')\n",
    "        \n",
    "        path = save_path + 'chart_{}.png'.format(i)\n",
    "        chart.chart_to_image(path)\n",
    "        paths_to_images.append(path)\n",
    "        i += 1\n",
    "    return paths_to_images        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec7236d0230c4717bc1e40c60266cc72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=4455), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-05d3bb5f1fce>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpaths_to_images\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_charts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcandles_sliced\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"images/\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-8-b543ac4573da>\u001b[0m in \u001b[0;36mcreate_charts\u001b[0;34m(candles_sliced, save_path)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msave_path\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'chart_{}.png'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mchart\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchart_to_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0mpaths_to_images\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mi\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/FALKOR/helpers/charting_tools.py\u001b[0m in \u001b[0;36mchart_to_image\u001b[0;34m(self, file_name)\u001b[0m\n\u001b[1;32m    230\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m         \u001b[0;31m# Plot Price\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 232\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcol_label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrow_label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0max0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'black'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'_nolegend_'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlinewidth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    233\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m         \u001b[0;31m# Plot Technical Indicators\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/pandas/plotting/_core.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    792\u001b[0m                     \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabel_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    793\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 794\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mplot_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkind\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkind\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    795\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    796\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/pandas/plotting/_matplotlib/__init__.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(data, kind, **kwargs)\u001b[0m\n\u001b[1;32m     60\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"ax\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"left_ax\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0mplot_obj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPLOT_CLASSES\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkind\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m     \u001b[0mplot_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m     \u001b[0mplot_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mplot_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/pandas/plotting/_matplotlib/core.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    277\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_args_adjust\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 279\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compute_plot_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    280\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setup_subplots\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_plot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/pandas/plotting/_matplotlib/core.py\u001b[0m in \u001b[0;36m_compute_plot_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    416\u001b[0m         \u001b[0;31m# GH25587: cast ExtensionArray of pandas (IntegerArray, etc.) to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m         \u001b[0;31m# np.ndarray before plot.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 418\u001b[0;31m         \u001b[0mnumeric_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumeric_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    419\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mcol\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnumeric_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    420\u001b[0m             \u001b[0mnumeric_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumeric_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mcopy\u001b[0;34m(self, deep)\u001b[0m\n\u001b[1;32m   5995\u001b[0m         \u001b[0mdtype\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5996\u001b[0m         \"\"\"\n\u001b[0;32m-> 5997\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdeep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdeep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5998\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_constructor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__finalize__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5999\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mcopy\u001b[0;34m(self, deep)\u001b[0m\n\u001b[1;32m    785\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    786\u001b[0m             \u001b[0mnew_axes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 787\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"copy\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnew_axes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdeep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdeep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdo_integrity_check\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    788\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    789\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mas_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtranspose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitems\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, f, axes, filter, do_integrity_check, consolidate, **kwargs)\u001b[0m\n\u001b[1;32m    442\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_empty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxes\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m         bm = self.__class__(\n\u001b[0;32m--> 444\u001b[0;31m             \u001b[0mresult_blocks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxes\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdo_integrity_check\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdo_integrity_check\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    445\u001b[0m         )\n\u001b[1;32m    446\u001b[0m         \u001b[0mbm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_consolidate_inplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, blocks, axes, do_integrity_check)\u001b[0m\n\u001b[1;32m    145\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_consolidate_check\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_rebuild_blknos_and_blklocs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmake_empty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36m_rebuild_blknos_and_blklocs\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    218\u001b[0m         \u001b[0mUpdate\u001b[0m \u001b[0mmgr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_blknos\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mmgr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_blklocs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m         \"\"\"\n\u001b[0;32m--> 220\u001b[0;31m         \u001b[0mnew_blknos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    221\u001b[0m         \u001b[0mnew_blklocs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m         \u001b[0mnew_blknos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfill\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mshape\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    167\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 169\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0max\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    167\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 169\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0max\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAV0AAAA9CAYAAAAOC7pZAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+17YcXAAAA60lEQVR4nO3UMQEAIAzAMMC/5+GiHCQKenXPzAKgcV4HAPzEdAFCpgsQMl2AkOkChEwXIGS6ACHTBQiZLkDIdAFCpgsQMl2AkOkChEwXIGS6ACHTBQiZLkDIdAFCpgsQMl2AkOkChEwXIGS6ACHTBQiZLkDIdAFCpgsQMl2AkOkChEwXIGS6ACHTBQiZLkDIdAFCpgsQMl2AkOkChEwXIGS6ACHTBQiZLkDIdAFCpgsQMl2AkOkChEwXIGS6ACHTBQiZLkDIdAFCpgsQMl2AkOkChEwXIGS6ACHTBQiZLkDIdAFCpgsQMl2A0AWT3gN39vnvvQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "paths_to_images = create_charts(candles_sliced, \"images/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths_to_images = [ 'images/chart_{}.png'.format(i) for i in range(len(candles_sliced)) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image.open(paths_to_images[100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_series(ser):\n",
    "    return (ser-ser.min())/(ser.max()-ser.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(44617, 11)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "try: candles = candles.drop('time', axis=1)\n",
    "except: pass\n",
    "candles.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>sma20</th>\n",
       "      <th>macd</th>\n",
       "      <th>obv</th>\n",
       "      <th>bb20_low</th>\n",
       "      <th>bb20_mid</th>\n",
       "      <th>bb20_up</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.483425</td>\n",
       "      <td>0.478847</td>\n",
       "      <td>0.483934</td>\n",
       "      <td>0.483534</td>\n",
       "      <td>0.002120</td>\n",
       "      <td>0.481723</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.801935</td>\n",
       "      <td>0.490334</td>\n",
       "      <td>0.481723</td>\n",
       "      <td>0.471502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.481645</td>\n",
       "      <td>0.478847</td>\n",
       "      <td>0.485969</td>\n",
       "      <td>0.482006</td>\n",
       "      <td>0.001175</td>\n",
       "      <td>0.482004</td>\n",
       "      <td>0.931537</td>\n",
       "      <td>0.801817</td>\n",
       "      <td>0.490739</td>\n",
       "      <td>0.482004</td>\n",
       "      <td>0.471657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.482832</td>\n",
       "      <td>0.478847</td>\n",
       "      <td>0.485969</td>\n",
       "      <td>0.481752</td>\n",
       "      <td>0.000969</td>\n",
       "      <td>0.482034</td>\n",
       "      <td>0.867900</td>\n",
       "      <td>0.801715</td>\n",
       "      <td>0.490748</td>\n",
       "      <td>0.482034</td>\n",
       "      <td>0.471708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.482577</td>\n",
       "      <td>0.477499</td>\n",
       "      <td>0.483934</td>\n",
       "      <td>0.480054</td>\n",
       "      <td>0.001445</td>\n",
       "      <td>0.482138</td>\n",
       "      <td>0.808804</td>\n",
       "      <td>0.801574</td>\n",
       "      <td>0.490940</td>\n",
       "      <td>0.482138</td>\n",
       "      <td>0.471724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.480882</td>\n",
       "      <td>0.475645</td>\n",
       "      <td>0.483934</td>\n",
       "      <td>0.480648</td>\n",
       "      <td>0.001579</td>\n",
       "      <td>0.482030</td>\n",
       "      <td>0.753974</td>\n",
       "      <td>0.801726</td>\n",
       "      <td>0.490802</td>\n",
       "      <td>0.482030</td>\n",
       "      <td>0.471646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.480967</td>\n",
       "      <td>0.478679</td>\n",
       "      <td>0.483849</td>\n",
       "      <td>0.481837</td>\n",
       "      <td>0.001824</td>\n",
       "      <td>0.481883</td>\n",
       "      <td>0.703138</td>\n",
       "      <td>0.801898</td>\n",
       "      <td>0.490868</td>\n",
       "      <td>0.481883</td>\n",
       "      <td>0.471290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.481984</td>\n",
       "      <td>0.476825</td>\n",
       "      <td>0.484273</td>\n",
       "      <td>0.482006</td>\n",
       "      <td>0.001095</td>\n",
       "      <td>0.481840</td>\n",
       "      <td>0.656034</td>\n",
       "      <td>0.802010</td>\n",
       "      <td>0.490910</td>\n",
       "      <td>0.481840</td>\n",
       "      <td>0.471163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.482069</td>\n",
       "      <td>0.478763</td>\n",
       "      <td>0.483849</td>\n",
       "      <td>0.482516</td>\n",
       "      <td>0.002209</td>\n",
       "      <td>0.481870</td>\n",
       "      <td>0.612416</td>\n",
       "      <td>0.802214</td>\n",
       "      <td>0.490907</td>\n",
       "      <td>0.481870</td>\n",
       "      <td>0.471225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.483425</td>\n",
       "      <td>0.478679</td>\n",
       "      <td>0.486138</td>\n",
       "      <td>0.482601</td>\n",
       "      <td>0.000909</td>\n",
       "      <td>0.482013</td>\n",
       "      <td>0.572046</td>\n",
       "      <td>0.802311</td>\n",
       "      <td>0.491060</td>\n",
       "      <td>0.482013</td>\n",
       "      <td>0.471357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.481984</td>\n",
       "      <td>0.478763</td>\n",
       "      <td>0.484273</td>\n",
       "      <td>0.482006</td>\n",
       "      <td>0.001753</td>\n",
       "      <td>0.482112</td>\n",
       "      <td>0.534702</td>\n",
       "      <td>0.802144</td>\n",
       "      <td>0.491101</td>\n",
       "      <td>0.482112</td>\n",
       "      <td>0.471512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.482916</td>\n",
       "      <td>0.478763</td>\n",
       "      <td>0.486308</td>\n",
       "      <td>0.482346</td>\n",
       "      <td>0.002359</td>\n",
       "      <td>0.482194</td>\n",
       "      <td>0.500174</td>\n",
       "      <td>0.802360</td>\n",
       "      <td>0.491205</td>\n",
       "      <td>0.482194</td>\n",
       "      <td>0.471572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.483171</td>\n",
       "      <td>0.478763</td>\n",
       "      <td>0.485714</td>\n",
       "      <td>0.483364</td>\n",
       "      <td>0.002130</td>\n",
       "      <td>0.482332</td>\n",
       "      <td>0.468262</td>\n",
       "      <td>0.802557</td>\n",
       "      <td>0.491457</td>\n",
       "      <td>0.482332</td>\n",
       "      <td>0.471596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.482832</td>\n",
       "      <td>0.478594</td>\n",
       "      <td>0.486477</td>\n",
       "      <td>0.483874</td>\n",
       "      <td>0.001663</td>\n",
       "      <td>0.482518</td>\n",
       "      <td>0.438778</td>\n",
       "      <td>0.802716</td>\n",
       "      <td>0.491672</td>\n",
       "      <td>0.482518</td>\n",
       "      <td>0.471751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.484188</td>\n",
       "      <td>0.478847</td>\n",
       "      <td>0.486816</td>\n",
       "      <td>0.483959</td>\n",
       "      <td>0.002796</td>\n",
       "      <td>0.482743</td>\n",
       "      <td>0.411545</td>\n",
       "      <td>0.802968</td>\n",
       "      <td>0.491963</td>\n",
       "      <td>0.482743</td>\n",
       "      <td>0.471907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.483680</td>\n",
       "      <td>0.478763</td>\n",
       "      <td>0.486816</td>\n",
       "      <td>0.482431</td>\n",
       "      <td>0.002342</td>\n",
       "      <td>0.482977</td>\n",
       "      <td>0.386400</td>\n",
       "      <td>0.802753</td>\n",
       "      <td>0.492368</td>\n",
       "      <td>0.482977</td>\n",
       "      <td>0.471968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.483595</td>\n",
       "      <td>0.478763</td>\n",
       "      <td>0.483849</td>\n",
       "      <td>0.481073</td>\n",
       "      <td>0.001800</td>\n",
       "      <td>0.483033</td>\n",
       "      <td>0.363193</td>\n",
       "      <td>0.802583</td>\n",
       "      <td>0.492460</td>\n",
       "      <td>0.483033</td>\n",
       "      <td>0.471989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.483595</td>\n",
       "      <td>0.478173</td>\n",
       "      <td>0.483849</td>\n",
       "      <td>0.482346</td>\n",
       "      <td>0.001796</td>\n",
       "      <td>0.483020</td>\n",
       "      <td>0.341783</td>\n",
       "      <td>0.802753</td>\n",
       "      <td>0.492421</td>\n",
       "      <td>0.483020</td>\n",
       "      <td>0.472002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.481814</td>\n",
       "      <td>0.476993</td>\n",
       "      <td>0.485206</td>\n",
       "      <td>0.482006</td>\n",
       "      <td>0.002015</td>\n",
       "      <td>0.483007</td>\n",
       "      <td>0.322033</td>\n",
       "      <td>0.802565</td>\n",
       "      <td>0.492415</td>\n",
       "      <td>0.483007</td>\n",
       "      <td>0.471982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.481730</td>\n",
       "      <td>0.478931</td>\n",
       "      <td>0.484951</td>\n",
       "      <td>0.484213</td>\n",
       "      <td>0.004664</td>\n",
       "      <td>0.483067</td>\n",
       "      <td>0.303819</td>\n",
       "      <td>0.802970</td>\n",
       "      <td>0.492575</td>\n",
       "      <td>0.483067</td>\n",
       "      <td>0.471943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.484358</td>\n",
       "      <td>0.483398</td>\n",
       "      <td>0.485375</td>\n",
       "      <td>0.486505</td>\n",
       "      <td>0.011560</td>\n",
       "      <td>0.483180</td>\n",
       "      <td>0.287019</td>\n",
       "      <td>0.803941</td>\n",
       "      <td>0.492511</td>\n",
       "      <td>0.483180</td>\n",
       "      <td>0.472229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.485799</td>\n",
       "      <td>0.482808</td>\n",
       "      <td>0.487410</td>\n",
       "      <td>0.486590</td>\n",
       "      <td>0.002356</td>\n",
       "      <td>0.483366</td>\n",
       "      <td>0.271523</td>\n",
       "      <td>0.804156</td>\n",
       "      <td>0.492019</td>\n",
       "      <td>0.483366</td>\n",
       "      <td>0.473084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.486647</td>\n",
       "      <td>0.482471</td>\n",
       "      <td>0.488343</td>\n",
       "      <td>0.485486</td>\n",
       "      <td>0.002278</td>\n",
       "      <td>0.483521</td>\n",
       "      <td>0.257232</td>\n",
       "      <td>0.803947</td>\n",
       "      <td>0.491672</td>\n",
       "      <td>0.483521</td>\n",
       "      <td>0.473734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.486053</td>\n",
       "      <td>0.481544</td>\n",
       "      <td>0.488258</td>\n",
       "      <td>0.486675</td>\n",
       "      <td>0.002656</td>\n",
       "      <td>0.483698</td>\n",
       "      <td>0.244057</td>\n",
       "      <td>0.804187</td>\n",
       "      <td>0.491648</td>\n",
       "      <td>0.483698</td>\n",
       "      <td>0.474109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.485714</td>\n",
       "      <td>0.481460</td>\n",
       "      <td>0.488682</td>\n",
       "      <td>0.486675</td>\n",
       "      <td>0.002137</td>\n",
       "      <td>0.483949</td>\n",
       "      <td>0.231910</td>\n",
       "      <td>0.804187</td>\n",
       "      <td>0.491564</td>\n",
       "      <td>0.483949</td>\n",
       "      <td>0.474688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0.486816</td>\n",
       "      <td>0.483482</td>\n",
       "      <td>0.491056</td>\n",
       "      <td>0.488372</td>\n",
       "      <td>0.001924</td>\n",
       "      <td>0.484286</td>\n",
       "      <td>0.220714</td>\n",
       "      <td>0.804367</td>\n",
       "      <td>0.491875</td>\n",
       "      <td>0.484286</td>\n",
       "      <td>0.475047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0.488512</td>\n",
       "      <td>0.483314</td>\n",
       "      <td>0.490377</td>\n",
       "      <td>0.485996</td>\n",
       "      <td>0.002841</td>\n",
       "      <td>0.484680</td>\n",
       "      <td>0.210392</td>\n",
       "      <td>0.804112</td>\n",
       "      <td>0.491929</td>\n",
       "      <td>0.484680</td>\n",
       "      <td>0.475772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0.486223</td>\n",
       "      <td>0.482892</td>\n",
       "      <td>0.490377</td>\n",
       "      <td>0.488033</td>\n",
       "      <td>0.001549</td>\n",
       "      <td>0.484891</td>\n",
       "      <td>0.200882</td>\n",
       "      <td>0.804261</td>\n",
       "      <td>0.492147</td>\n",
       "      <td>0.484891</td>\n",
       "      <td>0.475975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>0.488173</td>\n",
       "      <td>0.484325</td>\n",
       "      <td>0.490547</td>\n",
       "      <td>0.486759</td>\n",
       "      <td>0.003767</td>\n",
       "      <td>0.485198</td>\n",
       "      <td>0.192117</td>\n",
       "      <td>0.803930</td>\n",
       "      <td>0.492218</td>\n",
       "      <td>0.485198</td>\n",
       "      <td>0.476512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>0.487664</td>\n",
       "      <td>0.483314</td>\n",
       "      <td>0.491310</td>\n",
       "      <td>0.487863</td>\n",
       "      <td>0.003010</td>\n",
       "      <td>0.485414</td>\n",
       "      <td>0.184042</td>\n",
       "      <td>0.804199</td>\n",
       "      <td>0.492399</td>\n",
       "      <td>0.485414</td>\n",
       "      <td>0.476760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>0.488003</td>\n",
       "      <td>0.484241</td>\n",
       "      <td>0.492242</td>\n",
       "      <td>0.487948</td>\n",
       "      <td>0.001438</td>\n",
       "      <td>0.485682</td>\n",
       "      <td>0.176602</td>\n",
       "      <td>0.804340</td>\n",
       "      <td>0.492539</td>\n",
       "      <td>0.485682</td>\n",
       "      <td>0.477152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44611</th>\n",
       "      <td>0.093429</td>\n",
       "      <td>0.091859</td>\n",
       "      <td>0.096736</td>\n",
       "      <td>0.092769</td>\n",
       "      <td>0.004577</td>\n",
       "      <td>0.089662</td>\n",
       "      <td>0.161283</td>\n",
       "      <td>0.024823</td>\n",
       "      <td>0.099240</td>\n",
       "      <td>0.089662</td>\n",
       "      <td>0.082994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44612</th>\n",
       "      <td>0.094108</td>\n",
       "      <td>0.091943</td>\n",
       "      <td>0.098262</td>\n",
       "      <td>0.093787</td>\n",
       "      <td>0.000987</td>\n",
       "      <td>0.089446</td>\n",
       "      <td>0.161308</td>\n",
       "      <td>0.024926</td>\n",
       "      <td>0.098639</td>\n",
       "      <td>0.089446</td>\n",
       "      <td>0.083160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44613</th>\n",
       "      <td>0.094023</td>\n",
       "      <td>0.091185</td>\n",
       "      <td>0.096651</td>\n",
       "      <td>0.093448</td>\n",
       "      <td>0.002715</td>\n",
       "      <td>0.089304</td>\n",
       "      <td>0.161334</td>\n",
       "      <td>0.024681</td>\n",
       "      <td>0.098375</td>\n",
       "      <td>0.089304</td>\n",
       "      <td>0.083140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44614</th>\n",
       "      <td>0.093260</td>\n",
       "      <td>0.092280</td>\n",
       "      <td>0.097414</td>\n",
       "      <td>0.094721</td>\n",
       "      <td>0.006119</td>\n",
       "      <td>0.089131</td>\n",
       "      <td>0.161361</td>\n",
       "      <td>0.025205</td>\n",
       "      <td>0.098091</td>\n",
       "      <td>0.089131</td>\n",
       "      <td>0.083079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44615</th>\n",
       "      <td>0.094616</td>\n",
       "      <td>0.092955</td>\n",
       "      <td>0.098771</td>\n",
       "      <td>0.095060</td>\n",
       "      <td>0.003267</td>\n",
       "      <td>0.089066</td>\n",
       "      <td>0.161386</td>\n",
       "      <td>0.025496</td>\n",
       "      <td>0.098017</td>\n",
       "      <td>0.089066</td>\n",
       "      <td>0.083024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44616</th>\n",
       "      <td>0.095719</td>\n",
       "      <td>0.095314</td>\n",
       "      <td>0.099364</td>\n",
       "      <td>0.096503</td>\n",
       "      <td>0.005816</td>\n",
       "      <td>0.088997</td>\n",
       "      <td>0.161407</td>\n",
       "      <td>0.025995</td>\n",
       "      <td>0.097984</td>\n",
       "      <td>0.088997</td>\n",
       "      <td>0.082919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44617</th>\n",
       "      <td>0.097753</td>\n",
       "      <td>0.095062</td>\n",
       "      <td>0.101399</td>\n",
       "      <td>0.097437</td>\n",
       "      <td>0.001725</td>\n",
       "      <td>0.089031</td>\n",
       "      <td>0.161423</td>\n",
       "      <td>0.026159</td>\n",
       "      <td>0.097978</td>\n",
       "      <td>0.089031</td>\n",
       "      <td>0.082994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44618</th>\n",
       "      <td>0.097329</td>\n",
       "      <td>0.094893</td>\n",
       "      <td>0.100551</td>\n",
       "      <td>0.096588</td>\n",
       "      <td>0.003021</td>\n",
       "      <td>0.089126</td>\n",
       "      <td>0.161433</td>\n",
       "      <td>0.025889</td>\n",
       "      <td>0.097926</td>\n",
       "      <td>0.089126</td>\n",
       "      <td>0.083233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44619</th>\n",
       "      <td>0.097669</td>\n",
       "      <td>0.095146</td>\n",
       "      <td>0.101229</td>\n",
       "      <td>0.097691</td>\n",
       "      <td>0.002632</td>\n",
       "      <td>0.089183</td>\n",
       "      <td>0.161439</td>\n",
       "      <td>0.026127</td>\n",
       "      <td>0.097941</td>\n",
       "      <td>0.089183</td>\n",
       "      <td>0.083330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44620</th>\n",
       "      <td>0.097838</td>\n",
       "      <td>0.095567</td>\n",
       "      <td>0.101823</td>\n",
       "      <td>0.098031</td>\n",
       "      <td>0.003785</td>\n",
       "      <td>0.089325</td>\n",
       "      <td>0.161439</td>\n",
       "      <td>0.026460</td>\n",
       "      <td>0.097951</td>\n",
       "      <td>0.089325</td>\n",
       "      <td>0.083602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44621</th>\n",
       "      <td>0.098601</td>\n",
       "      <td>0.095736</td>\n",
       "      <td>0.101908</td>\n",
       "      <td>0.097267</td>\n",
       "      <td>0.001955</td>\n",
       "      <td>0.089351</td>\n",
       "      <td>0.161435</td>\n",
       "      <td>0.026277</td>\n",
       "      <td>0.097906</td>\n",
       "      <td>0.089351</td>\n",
       "      <td>0.083698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44622</th>\n",
       "      <td>0.097838</td>\n",
       "      <td>0.095483</td>\n",
       "      <td>0.101992</td>\n",
       "      <td>0.097182</td>\n",
       "      <td>0.000897</td>\n",
       "      <td>0.089386</td>\n",
       "      <td>0.161429</td>\n",
       "      <td>0.026181</td>\n",
       "      <td>0.097887</td>\n",
       "      <td>0.089386</td>\n",
       "      <td>0.083785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44623</th>\n",
       "      <td>0.097753</td>\n",
       "      <td>0.095651</td>\n",
       "      <td>0.101992</td>\n",
       "      <td>0.097097</td>\n",
       "      <td>0.001430</td>\n",
       "      <td>0.089381</td>\n",
       "      <td>0.161421</td>\n",
       "      <td>0.026042</td>\n",
       "      <td>0.097891</td>\n",
       "      <td>0.089381</td>\n",
       "      <td>0.083773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44624</th>\n",
       "      <td>0.097753</td>\n",
       "      <td>0.094640</td>\n",
       "      <td>0.101229</td>\n",
       "      <td>0.096418</td>\n",
       "      <td>0.001462</td>\n",
       "      <td>0.089442</td>\n",
       "      <td>0.161413</td>\n",
       "      <td>0.025899</td>\n",
       "      <td>0.097895</td>\n",
       "      <td>0.089442</td>\n",
       "      <td>0.083889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44625</th>\n",
       "      <td>0.096905</td>\n",
       "      <td>0.094303</td>\n",
       "      <td>0.100890</td>\n",
       "      <td>0.095994</td>\n",
       "      <td>0.001791</td>\n",
       "      <td>0.089403</td>\n",
       "      <td>0.161406</td>\n",
       "      <td>0.025730</td>\n",
       "      <td>0.097906</td>\n",
       "      <td>0.089403</td>\n",
       "      <td>0.083800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44626</th>\n",
       "      <td>0.097329</td>\n",
       "      <td>0.094219</td>\n",
       "      <td>0.099534</td>\n",
       "      <td>0.095654</td>\n",
       "      <td>0.002840</td>\n",
       "      <td>0.089377</td>\n",
       "      <td>0.161400</td>\n",
       "      <td>0.025475</td>\n",
       "      <td>0.097897</td>\n",
       "      <td>0.089377</td>\n",
       "      <td>0.083758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44627</th>\n",
       "      <td>0.096227</td>\n",
       "      <td>0.094219</td>\n",
       "      <td>0.099618</td>\n",
       "      <td>0.096418</td>\n",
       "      <td>0.005685</td>\n",
       "      <td>0.089373</td>\n",
       "      <td>0.161397</td>\n",
       "      <td>0.025963</td>\n",
       "      <td>0.097893</td>\n",
       "      <td>0.089373</td>\n",
       "      <td>0.083754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44628</th>\n",
       "      <td>0.097329</td>\n",
       "      <td>0.094893</td>\n",
       "      <td>0.100636</td>\n",
       "      <td>0.096503</td>\n",
       "      <td>0.002873</td>\n",
       "      <td>0.089412</td>\n",
       "      <td>0.161394</td>\n",
       "      <td>0.026221</td>\n",
       "      <td>0.097917</td>\n",
       "      <td>0.089412</td>\n",
       "      <td>0.083807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44629</th>\n",
       "      <td>0.097753</td>\n",
       "      <td>0.094724</td>\n",
       "      <td>0.095719</td>\n",
       "      <td>0.095654</td>\n",
       "      <td>0.016475</td>\n",
       "      <td>0.089455</td>\n",
       "      <td>0.161391</td>\n",
       "      <td>0.024848</td>\n",
       "      <td>0.097944</td>\n",
       "      <td>0.089455</td>\n",
       "      <td>0.083866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44630</th>\n",
       "      <td>0.096566</td>\n",
       "      <td>0.093545</td>\n",
       "      <td>0.099025</td>\n",
       "      <td>0.094636</td>\n",
       "      <td>0.002085</td>\n",
       "      <td>0.089511</td>\n",
       "      <td>0.161390</td>\n",
       "      <td>0.024655</td>\n",
       "      <td>0.098052</td>\n",
       "      <td>0.089511</td>\n",
       "      <td>0.083870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44631</th>\n",
       "      <td>0.095210</td>\n",
       "      <td>0.094219</td>\n",
       "      <td>0.098771</td>\n",
       "      <td>0.095485</td>\n",
       "      <td>0.004929</td>\n",
       "      <td>0.089597</td>\n",
       "      <td>0.161392</td>\n",
       "      <td>0.025081</td>\n",
       "      <td>0.098384</td>\n",
       "      <td>0.089597</td>\n",
       "      <td>0.083712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44632</th>\n",
       "      <td>0.096821</td>\n",
       "      <td>0.093713</td>\n",
       "      <td>0.098432</td>\n",
       "      <td>0.094721</td>\n",
       "      <td>0.001281</td>\n",
       "      <td>0.089736</td>\n",
       "      <td>0.161396</td>\n",
       "      <td>0.024954</td>\n",
       "      <td>0.098913</td>\n",
       "      <td>0.089736</td>\n",
       "      <td>0.083463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44633</th>\n",
       "      <td>0.094786</td>\n",
       "      <td>0.092449</td>\n",
       "      <td>0.098686</td>\n",
       "      <td>0.093957</td>\n",
       "      <td>0.001657</td>\n",
       "      <td>0.089783</td>\n",
       "      <td>0.161402</td>\n",
       "      <td>0.024795</td>\n",
       "      <td>0.099106</td>\n",
       "      <td>0.089783</td>\n",
       "      <td>0.083365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44634</th>\n",
       "      <td>0.094616</td>\n",
       "      <td>0.092112</td>\n",
       "      <td>0.098855</td>\n",
       "      <td>0.094636</td>\n",
       "      <td>0.000974</td>\n",
       "      <td>0.089809</td>\n",
       "      <td>0.161411</td>\n",
       "      <td>0.024898</td>\n",
       "      <td>0.099243</td>\n",
       "      <td>0.089809</td>\n",
       "      <td>0.083281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44635</th>\n",
       "      <td>0.095210</td>\n",
       "      <td>0.093545</td>\n",
       "      <td>0.099364</td>\n",
       "      <td>0.095909</td>\n",
       "      <td>0.002848</td>\n",
       "      <td>0.089805</td>\n",
       "      <td>0.161422</td>\n",
       "      <td>0.025154</td>\n",
       "      <td>0.099228</td>\n",
       "      <td>0.089805</td>\n",
       "      <td>0.083288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44636</th>\n",
       "      <td>0.095973</td>\n",
       "      <td>0.094135</td>\n",
       "      <td>0.100297</td>\n",
       "      <td>0.096588</td>\n",
       "      <td>0.002492</td>\n",
       "      <td>0.089848</td>\n",
       "      <td>0.161431</td>\n",
       "      <td>0.025380</td>\n",
       "      <td>0.099324</td>\n",
       "      <td>0.089848</td>\n",
       "      <td>0.083278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44637</th>\n",
       "      <td>0.097160</td>\n",
       "      <td>0.094135</td>\n",
       "      <td>0.100975</td>\n",
       "      <td>0.096249</td>\n",
       "      <td>0.004626</td>\n",
       "      <td>0.089852</td>\n",
       "      <td>0.161436</td>\n",
       "      <td>0.024979</td>\n",
       "      <td>0.099326</td>\n",
       "      <td>0.089852</td>\n",
       "      <td>0.083285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44638</th>\n",
       "      <td>0.096821</td>\n",
       "      <td>0.094219</td>\n",
       "      <td>0.100382</td>\n",
       "      <td>0.095909</td>\n",
       "      <td>0.003969</td>\n",
       "      <td>0.089792</td>\n",
       "      <td>0.161439</td>\n",
       "      <td>0.024631</td>\n",
       "      <td>0.099342</td>\n",
       "      <td>0.089792</td>\n",
       "      <td>0.083149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44639</th>\n",
       "      <td>0.097329</td>\n",
       "      <td>0.094556</td>\n",
       "      <td>0.100382</td>\n",
       "      <td>0.096079</td>\n",
       "      <td>0.004646</td>\n",
       "      <td>0.089757</td>\n",
       "      <td>0.161442</td>\n",
       "      <td>0.025034</td>\n",
       "      <td>0.099316</td>\n",
       "      <td>0.089757</td>\n",
       "      <td>0.083106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44640</th>\n",
       "      <td>0.097499</td>\n",
       "      <td>0.095567</td>\n",
       "      <td>0.100551</td>\n",
       "      <td>0.096843</td>\n",
       "      <td>0.011170</td>\n",
       "      <td>0.089675</td>\n",
       "      <td>0.161444</td>\n",
       "      <td>0.025973</td>\n",
       "      <td>0.099367</td>\n",
       "      <td>0.089675</td>\n",
       "      <td>0.082893</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>44617 rows  11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           open      high       low     close    volume     sma20      macd  \\\n",
       "24     0.483425  0.478847  0.483934  0.483534  0.002120  0.481723  1.000000   \n",
       "25     0.481645  0.478847  0.485969  0.482006  0.001175  0.482004  0.931537   \n",
       "26     0.482832  0.478847  0.485969  0.481752  0.000969  0.482034  0.867900   \n",
       "27     0.482577  0.477499  0.483934  0.480054  0.001445  0.482138  0.808804   \n",
       "28     0.480882  0.475645  0.483934  0.480648  0.001579  0.482030  0.753974   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "44636  0.095973  0.094135  0.100297  0.096588  0.002492  0.089848  0.161431   \n",
       "44637  0.097160  0.094135  0.100975  0.096249  0.004626  0.089852  0.161436   \n",
       "44638  0.096821  0.094219  0.100382  0.095909  0.003969  0.089792  0.161439   \n",
       "44639  0.097329  0.094556  0.100382  0.096079  0.004646  0.089757  0.161442   \n",
       "44640  0.097499  0.095567  0.100551  0.096843  0.011170  0.089675  0.161444   \n",
       "\n",
       "            obv  bb20_low  bb20_mid   bb20_up  \n",
       "24     0.801935  0.490334  0.481723  0.471502  \n",
       "25     0.801817  0.490739  0.482004  0.471657  \n",
       "26     0.801715  0.490748  0.482034  0.471708  \n",
       "27     0.801574  0.490940  0.482138  0.471724  \n",
       "28     0.801726  0.490802  0.482030  0.471646  \n",
       "...         ...       ...       ...       ...  \n",
       "44636  0.025380  0.099324  0.089848  0.083278  \n",
       "44637  0.024979  0.099326  0.089852  0.083285  \n",
       "44638  0.024631  0.099342  0.089792  0.083149  \n",
       "44639  0.025034  0.099316  0.089757  0.083106  \n",
       "44640  0.025973  0.099367  0.089675  0.082893  \n",
       "\n",
       "[44617 rows x 11 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "candles.apply(normalize_series, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "# Parameters\n",
    "params = {'batch_size': 64,\n",
    "          'shuffle': True,\n",
    "          'num_workers': 5}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _train(train_gen, model, optim, error_func):\n",
    "    losses = []\n",
    "    \n",
    "    for batch, labels in train_gen:\n",
    "        batch, labels = batch.cuda().float(), labels.cuda().float()\n",
    "        # set model to train mode\n",
    "        model.train()\n",
    "        \n",
    "        # clear gradients\n",
    "        model.zero_grad()\n",
    "        \n",
    "        output = model(batch)\n",
    "        loss = error_func(output, labels)\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        \n",
    "        \n",
    "        losses.append(loss)\n",
    "        \n",
    "    return round(float(sum(losses) / len(losses)), 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _valid(valid_gen, model, optim, error_func):\n",
    "    with torch.set_grad_enabled(False):\n",
    "        losses = []\n",
    "\n",
    "        for batch, labels in valid_gen:\n",
    "            batch, labels = batch.cuda().float(), labels.cuda().float()\n",
    "            \n",
    "            # set to eval mode\n",
    "            model.eval()\n",
    "            \n",
    "            # clear gradients\n",
    "            model.zero_grad()\n",
    "\n",
    "            output = model(batch)\n",
    "            loss = error_func(output, labels)\n",
    "\n",
    "            losses.append(loss)\n",
    "        \n",
    "    return round(float(sum(losses) / len(losses)), 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _test(test_gen, model, optim, error_func):\n",
    "    with torch.set_grad_enabled(False):\n",
    "        losses = []\n",
    "\n",
    "        for batch, labels in valid_gen:\n",
    "            batch, labels = batch.cuda().float(), labels.cuda().float()\n",
    "            \n",
    "            # set to eval mode\n",
    "            model.eval()\n",
    "            \n",
    "            # clear gradients\n",
    "            model.zero_grad()\n",
    "\n",
    "            output = model(batch)\n",
    "            loss = error_func(output, labels)\n",
    "\n",
    "            losses.append(loss)\n",
    "        \n",
    "    return round(float(sum(losses) / len(losses)), 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, model_name, optim, num_epochs, train_gen, valid_gen, test_gen=None):\n",
    "    \"\"\"Train a PyTorch model with optim as optimizer strategy\"\"\"\n",
    "    \n",
    "    for epoch_i in range(num_epochs):\n",
    "        \n",
    "        \n",
    "        def RMSE(x, y):\n",
    "            \n",
    "            # have to squish x into a rank 1 tensor with batch_size length with the outputs we want\n",
    "            if model_name == 'resnet':\n",
    "                 # torch.Size([64, 1])\n",
    "                x = x.squeeze(1)\n",
    "            elif model_name == 'gru':\n",
    "                # torch.Size([64, 30, 1])\n",
    "                x = x[:, 29, :] # take only the last prediction from the 30 time periods in our matrix\n",
    "                x = x.squeeze(1)\n",
    "            mse = torch.nn.MSELoss()\n",
    "            return torch.sqrt(mse(x, y))\n",
    "        \n",
    "        \n",
    "        # forward and backward passes of all batches inside train_gen\n",
    "        train_loss = _train(train_gen, model, optim, RMSE)\n",
    "        valid_loss = _valid(valid_gen, model, optim, RMSE)\n",
    "        \n",
    "        # run on test set if provided\n",
    "        if test_gen: test_output = _test(test_gen, model, optim)\n",
    "        else: test_output = \"no test selected\"\n",
    "        print(\"train loss: {}, valid loss: {}, test output: {}\".format(train_loss, valid_loss, test_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.CNN.CNN import CNN\n",
    "cnn = CNN().cuda().float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers.datasets import DFTimeSeriesDataset, ChartImageDataset\n",
    "from torch.utils.data import *\n",
    "# create dataloaders\n",
    "# specify the split between train_df and valid_df from the process of splitting dataset_windows \n",
    "split = 0.7\n",
    "\n",
    "s = int(len(candles_sliced) * 0.7)\n",
    "while s % params['batch_size'] != 0:\n",
    "    s += 1\n",
    "\n",
    "# create two ChartImageDatasets, split by split, for the purpose of creating a DataLoader for the specific model\n",
    "train_ds_cnn = ChartImageDataset(paths_to_images[:s], labels_candles_sliced[:s])\n",
    "valid_ds_cnn = ChartImageDataset(paths_to_images[s:], labels_candles_sliced[s:])\n",
    "train_gen_cnn = DataLoader(train_ds_cnn, **params)\n",
    "valid_gen_cnn = DataLoader(valid_ds_cnn, **params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(cnn, 'resnet', torch.optim.Adam(cnn.parameters(), 1e-3), 15, train_gen_cnn, valid_gen_cnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.GRU.GRU import GRUnet\n",
    "gru = GRUnet(num_features=12, num_rows=30, batch_size=64, hidden_size=500, num_layers=1).cuda().float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers.datasets import DFTimeSeriesDataset, ChartImageDataset\n",
    "from torch.utils.data import *\n",
    "# create dataloaders\n",
    "# specify the split between train_df and valid_df from the process of splitting dataset_windows \n",
    "split = 0.7\n",
    "\n",
    "s = int(len(candles_sliced) * 0.7)\n",
    "while s % params['batch_size'] != 0:\n",
    "    s += 1\n",
    "\n",
    "# create two ChartImageDatasets, split by split, for the purpose of creating a DataLoader for the specific model\n",
    "train_ds_gru = DFTimeSeriesDataset(candles_sliced[:s], labels_candles_sliced[:s])\n",
    "valid_ds_gru = DFTimeSeriesDataset(candles_sliced[s:], labels_candles_sliced[s:])\n",
    "train_gen_gru = DataLoader(train_ds_gru, **params, drop_last=True)\n",
    "valid_gen_gru = DataLoader(valid_ds_gru, **params, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected hidden size (1, 39, 500), got (1, 64, 500)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-4f0645b82240>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgru\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'gru'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgru\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1e-3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_gen_gru\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_gen_gru\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-17-8b8e5b96acd5>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, model_name, optim, num_epochs, train_gen, valid_gen, test_gen)\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;31m# forward and backward passes of all batches inside train_gen\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_gen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRMSE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0mvalid_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_valid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_gen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRMSE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;31m# run on test set if provided\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-15-586ed048a5eb>\u001b[0m in \u001b[0;36m_valid\u001b[0;34m(valid_gen, model, optim, error_func)\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0merror_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/FALKOR/models/GRU/GRU.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     39\u001b[0m                 \u001b[0;34m\"\"\"Perform a forward pass of our model on some input and hidden state\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m                 \u001b[0;31m# GRU layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m                 \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m                 \u001b[0;31m# detatch the hidden layer to prevent further backpropagating. i.e. fix the vanishing gradient problem\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    726\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_packed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    727\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 728\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    729\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    730\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward_tensor\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    718\u001b[0m         \u001b[0msorted_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    719\u001b[0m         \u001b[0munsorted_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 720\u001b[0;31m         \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_batch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msorted_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    721\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute_hidden\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munsorted_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    722\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward_impl\u001b[0;34m(self, input, hx, batch_sizes, max_batch_size, sorted_indices)\u001b[0m\n\u001b[1;32m    695\u001b[0m             \u001b[0mhx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute_hidden\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msorted_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    696\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 697\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_forward_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    698\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    699\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mcheck_forward_args\u001b[0;34m(self, input, hidden, batch_sizes)\u001b[0m\n\u001b[1;32m    171\u001b[0m         \u001b[0mexpected_hidden_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_expected_hidden_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_hidden_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpected_hidden_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    174\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpermute_hidden\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpermutation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mcheck_hidden_size\u001b[0;34m(self, hx, expected_hidden_size, msg)\u001b[0m\n\u001b[1;32m    164\u001b[0m         \u001b[0;31m# type: (Tensor, Tuple[int, int, int], str) -> None\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mexpected_hidden_size\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexpected_hidden_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcheck_forward_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected hidden size (1, 39, 500), got (1, 64, 500)"
     ]
    }
   ],
   "source": [
    "train(gru, 'gru', torch.optim.Adam(gru.parameters(), 1e-3), 50, train_gen_gru, valid_gen_gru)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
