{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers.charting_tools import Charting\n",
    "from helpers.data_processing import add_ti\n",
    "from BookWorm import BookWorm, BinanceWrapper\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "worm = BookWorm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "candles = worm.historical_candles(start_time='January 1 2018', end_time='February 1 2019', api_wrapper=BinanceWrapper('5lJ0uGit9PuUxHka3hBWhPmsi7dWyxEwvEntUZFKmm0xfNz3VjHWi5WSr5W1VBJV',\n",
    "                                                      'BFWVs8ko7Cd4sjdQ9amGJTnToGWy9TbQWIjeorSCj23FGiwFaknzkgLPcrgWrxsw'), \n",
    "                  symbol='ETHBTC', interval='1m')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "candles = add_ti(candles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_candles(df, num_rows=30, step=10):\n",
    "    \"\"\"Split a DataFrame of candlestick data into a list of smaller DataFrames each with num_rows rows\"\"\"\n",
    "    \n",
    "    slices = []\n",
    "    \n",
    "    for row_i in range(0, df.shape[0] - num_rows, step):\n",
    "        small_df = df.iloc[row_i:row_i+num_rows, :]\n",
    "        slices.append(small_df)\n",
    "        \n",
    "    return slices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def price_returns(df, num_rows=30, num_into_fut=5, step=10):\n",
    "    labels = []\n",
    "    \n",
    "    for row_i in range(0, df.shape[0] - num_rows - num_into_fut, step):\n",
    "        # skip all iterations while row_i < num_rows since nothing yet to create a label for\n",
    "        if row_i <= num_rows: continue\n",
    "        \n",
    "        vf, vi = df['close'][row_i+num_into_fut], df['close'][row_i]\n",
    "        price_return = (vf - vi) / vi\n",
    "        labels.append(price_return)\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "56677"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# split candles into 30 period and a label\n",
    "candles_sliced = split_candles(candles)\n",
    "labels_candles_sliced = price_returns(candles)\n",
    "# we need to remove candle slices without a label from candles_sliced\n",
    "candles_sliced = candles_sliced[len(candles_sliced)-len(labels_candles_sliced):]\n",
    "\n",
    "assert len(candles_sliced) == len(labels_candles_sliced)\n",
    "len(candles_sliced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_charts(candles_sliced, save_path):\n",
    "    \"\"\"Create a chart image for each in sliced_candles and return a list of paths to those images\"\"\"\n",
    "    from tqdm import tqdm_notebook as tqdm\n",
    "    import warnings\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    \n",
    "    i = 0\n",
    "    paths_to_images = []\n",
    "    for small_df in tqdm(candles_sliced):\n",
    "        chart = Charting(small_df, 'time', 'close')\n",
    "        \n",
    "        path = save_path + 'chart_{}.png'.format(i)\n",
    "        chart.chart_to_image(path)\n",
    "        paths_to_images.append(path)\n",
    "        i += 1\n",
    "    return paths_to_images        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec7236d0230c4717bc1e40c60266cc72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=4455), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-05d3bb5f1fce>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpaths_to_images\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_charts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcandles_sliced\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"images/\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-8-b543ac4573da>\u001b[0m in \u001b[0;36mcreate_charts\u001b[0;34m(candles_sliced, save_path)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msave_path\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'chart_{}.png'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mchart\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchart_to_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0mpaths_to_images\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mi\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/FALKOR/helpers/charting_tools.py\u001b[0m in \u001b[0;36mchart_to_image\u001b[0;34m(self, file_name)\u001b[0m\n\u001b[1;32m    230\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m         \u001b[0;31m# Plot Price\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 232\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcol_label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrow_label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0max0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'black'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'_nolegend_'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlinewidth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    233\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m         \u001b[0;31m# Plot Technical Indicators\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/pandas/plotting/_core.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    792\u001b[0m                     \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabel_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    793\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 794\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mplot_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkind\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkind\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    795\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    796\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/pandas/plotting/_matplotlib/__init__.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(data, kind, **kwargs)\u001b[0m\n\u001b[1;32m     60\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"ax\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"left_ax\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0mplot_obj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPLOT_CLASSES\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkind\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m     \u001b[0mplot_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m     \u001b[0mplot_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mplot_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/pandas/plotting/_matplotlib/core.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    277\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_args_adjust\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 279\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compute_plot_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    280\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setup_subplots\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_plot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/pandas/plotting/_matplotlib/core.py\u001b[0m in \u001b[0;36m_compute_plot_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    416\u001b[0m         \u001b[0;31m# GH25587: cast ExtensionArray of pandas (IntegerArray, etc.) to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m         \u001b[0;31m# np.ndarray before plot.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 418\u001b[0;31m         \u001b[0mnumeric_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumeric_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    419\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mcol\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnumeric_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    420\u001b[0m             \u001b[0mnumeric_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumeric_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mcopy\u001b[0;34m(self, deep)\u001b[0m\n\u001b[1;32m   5995\u001b[0m         \u001b[0mdtype\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5996\u001b[0m         \"\"\"\n\u001b[0;32m-> 5997\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdeep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdeep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5998\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_constructor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__finalize__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5999\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mcopy\u001b[0;34m(self, deep)\u001b[0m\n\u001b[1;32m    785\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    786\u001b[0m             \u001b[0mnew_axes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 787\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"copy\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnew_axes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdeep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdeep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdo_integrity_check\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    788\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    789\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mas_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtranspose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitems\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, f, axes, filter, do_integrity_check, consolidate, **kwargs)\u001b[0m\n\u001b[1;32m    442\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_empty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxes\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m         bm = self.__class__(\n\u001b[0;32m--> 444\u001b[0;31m             \u001b[0mresult_blocks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxes\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdo_integrity_check\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdo_integrity_check\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    445\u001b[0m         )\n\u001b[1;32m    446\u001b[0m         \u001b[0mbm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_consolidate_inplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, blocks, axes, do_integrity_check)\u001b[0m\n\u001b[1;32m    145\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_consolidate_check\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_rebuild_blknos_and_blklocs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmake_empty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36m_rebuild_blknos_and_blklocs\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    218\u001b[0m         \u001b[0mUpdate\u001b[0m \u001b[0mmgr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_blknos\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mmgr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_blklocs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m         \"\"\"\n\u001b[0;32m--> 220\u001b[0;31m         \u001b[0mnew_blknos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    221\u001b[0m         \u001b[0mnew_blklocs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m         \u001b[0mnew_blknos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfill\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mshape\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    167\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 169\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0max\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    167\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 169\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0max\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAV0AAAA9CAYAAAAOC7pZAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+17YcXAAAA60lEQVR4nO3UMQEAIAzAMMC/5+GiHCQKenXPzAKgcV4HAPzEdAFCpgsQMl2AkOkChEwXIGS6ACHTBQiZLkDIdAFCpgsQMl2AkOkChEwXIGS6ACHTBQiZLkDIdAFCpgsQMl2AkOkChEwXIGS6ACHTBQiZLkDIdAFCpgsQMl2AkOkChEwXIGS6ACHTBQiZLkDIdAFCpgsQMl2AkOkChEwXIGS6ACHTBQiZLkDIdAFCpgsQMl2AkOkChEwXIGS6ACHTBQiZLkDIdAFCpgsQMl2AkOkChEwXIGS6ACHTBQiZLkDIdAFCpgsQMl2A0AWT3gN39vnvvQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "paths_to_images = create_charts(candles_sliced, \"images/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths_to_images = [ 'images/chart_{}.png'.format(i) for i in range(len(candles_sliced)) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image.open(paths_to_images[100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_series(ser):\n",
    "    return (ser-ser.min())/(ser.max()-ser.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(566841, 11)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "try: candles = candles.drop('time', axis=1)\n",
    "except: pass\n",
    "candles.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>sma20</th>\n",
       "      <th>macd</th>\n",
       "      <th>obv</th>\n",
       "      <th>bb20_low</th>\n",
       "      <th>bb20_mid</th>\n",
       "      <th>bb20_up</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.294695</td>\n",
       "      <td>0.294816</td>\n",
       "      <td>0.295438</td>\n",
       "      <td>0.294691</td>\n",
       "      <td>0.007892</td>\n",
       "      <td>0.297465</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.724619</td>\n",
       "      <td>0.298127</td>\n",
       "      <td>0.297465</td>\n",
       "      <td>0.294494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.294988</td>\n",
       "      <td>0.294634</td>\n",
       "      <td>0.294983</td>\n",
       "      <td>0.294267</td>\n",
       "      <td>0.010340</td>\n",
       "      <td>0.297578</td>\n",
       "      <td>0.957259</td>\n",
       "      <td>0.724342</td>\n",
       "      <td>0.298357</td>\n",
       "      <td>0.297578</td>\n",
       "      <td>0.294490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.294766</td>\n",
       "      <td>0.294846</td>\n",
       "      <td>0.293143</td>\n",
       "      <td>0.294024</td>\n",
       "      <td>0.016392</td>\n",
       "      <td>0.297686</td>\n",
       "      <td>0.917540</td>\n",
       "      <td>0.723903</td>\n",
       "      <td>0.298665</td>\n",
       "      <td>0.297686</td>\n",
       "      <td>0.294401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.293887</td>\n",
       "      <td>0.293807</td>\n",
       "      <td>0.292859</td>\n",
       "      <td>0.293479</td>\n",
       "      <td>0.007877</td>\n",
       "      <td>0.297774</td>\n",
       "      <td>0.880663</td>\n",
       "      <td>0.723693</td>\n",
       "      <td>0.298952</td>\n",
       "      <td>0.297774</td>\n",
       "      <td>0.294294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.293281</td>\n",
       "      <td>0.293565</td>\n",
       "      <td>0.293355</td>\n",
       "      <td>0.293479</td>\n",
       "      <td>0.010889</td>\n",
       "      <td>0.297817</td>\n",
       "      <td>0.846456</td>\n",
       "      <td>0.723693</td>\n",
       "      <td>0.299108</td>\n",
       "      <td>0.297817</td>\n",
       "      <td>0.294225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.293271</td>\n",
       "      <td>0.294181</td>\n",
       "      <td>0.293699</td>\n",
       "      <td>0.293772</td>\n",
       "      <td>0.011751</td>\n",
       "      <td>0.297832</td>\n",
       "      <td>0.814750</td>\n",
       "      <td>0.724007</td>\n",
       "      <td>0.299157</td>\n",
       "      <td>0.297832</td>\n",
       "      <td>0.294206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.293786</td>\n",
       "      <td>0.294382</td>\n",
       "      <td>0.294073</td>\n",
       "      <td>0.294034</td>\n",
       "      <td>0.017002</td>\n",
       "      <td>0.297848</td>\n",
       "      <td>0.785378</td>\n",
       "      <td>0.724462</td>\n",
       "      <td>0.299204</td>\n",
       "      <td>0.297848</td>\n",
       "      <td>0.294193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.294604</td>\n",
       "      <td>0.294645</td>\n",
       "      <td>0.294781</td>\n",
       "      <td>0.294701</td>\n",
       "      <td>0.008270</td>\n",
       "      <td>0.297926</td>\n",
       "      <td>0.758183</td>\n",
       "      <td>0.724683</td>\n",
       "      <td>0.299497</td>\n",
       "      <td>0.297926</td>\n",
       "      <td>0.294060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.294695</td>\n",
       "      <td>0.294826</td>\n",
       "      <td>0.294821</td>\n",
       "      <td>0.294620</td>\n",
       "      <td>0.015599</td>\n",
       "      <td>0.298031</td>\n",
       "      <td>0.733012</td>\n",
       "      <td>0.724266</td>\n",
       "      <td>0.299850</td>\n",
       "      <td>0.298031</td>\n",
       "      <td>0.293920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.294634</td>\n",
       "      <td>0.294463</td>\n",
       "      <td>0.293527</td>\n",
       "      <td>0.293984</td>\n",
       "      <td>0.018777</td>\n",
       "      <td>0.298077</td>\n",
       "      <td>0.709726</td>\n",
       "      <td>0.723763</td>\n",
       "      <td>0.299970</td>\n",
       "      <td>0.298077</td>\n",
       "      <td>0.293893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.293998</td>\n",
       "      <td>0.295351</td>\n",
       "      <td>0.294478</td>\n",
       "      <td>0.294479</td>\n",
       "      <td>0.010228</td>\n",
       "      <td>0.298022</td>\n",
       "      <td>0.688200</td>\n",
       "      <td>0.724037</td>\n",
       "      <td>0.299875</td>\n",
       "      <td>0.298022</td>\n",
       "      <td>0.293878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.294493</td>\n",
       "      <td>0.294836</td>\n",
       "      <td>0.294892</td>\n",
       "      <td>0.294438</td>\n",
       "      <td>0.007775</td>\n",
       "      <td>0.297997</td>\n",
       "      <td>0.668306</td>\n",
       "      <td>0.723829</td>\n",
       "      <td>0.299847</td>\n",
       "      <td>0.297997</td>\n",
       "      <td>0.293858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.294392</td>\n",
       "      <td>0.295502</td>\n",
       "      <td>0.295084</td>\n",
       "      <td>0.294671</td>\n",
       "      <td>0.010004</td>\n",
       "      <td>0.297957</td>\n",
       "      <td>0.649926</td>\n",
       "      <td>0.724097</td>\n",
       "      <td>0.299815</td>\n",
       "      <td>0.297957</td>\n",
       "      <td>0.293809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.294665</td>\n",
       "      <td>0.295068</td>\n",
       "      <td>0.294842</td>\n",
       "      <td>0.295458</td>\n",
       "      <td>0.009563</td>\n",
       "      <td>0.297925</td>\n",
       "      <td>0.632949</td>\n",
       "      <td>0.724353</td>\n",
       "      <td>0.299804</td>\n",
       "      <td>0.297925</td>\n",
       "      <td>0.293757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.294372</td>\n",
       "      <td>0.295240</td>\n",
       "      <td>0.295105</td>\n",
       "      <td>0.295489</td>\n",
       "      <td>0.007541</td>\n",
       "      <td>0.297878</td>\n",
       "      <td>0.617268</td>\n",
       "      <td>0.724554</td>\n",
       "      <td>0.299907</td>\n",
       "      <td>0.297878</td>\n",
       "      <td>0.293563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.295503</td>\n",
       "      <td>0.295099</td>\n",
       "      <td>0.295135</td>\n",
       "      <td>0.294388</td>\n",
       "      <td>0.008403</td>\n",
       "      <td>0.297858</td>\n",
       "      <td>0.602789</td>\n",
       "      <td>0.724330</td>\n",
       "      <td>0.299944</td>\n",
       "      <td>0.297858</td>\n",
       "      <td>0.293488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.294402</td>\n",
       "      <td>0.294524</td>\n",
       "      <td>0.294660</td>\n",
       "      <td>0.294842</td>\n",
       "      <td>0.007189</td>\n",
       "      <td>0.297767</td>\n",
       "      <td>0.589431</td>\n",
       "      <td>0.724522</td>\n",
       "      <td>0.300043</td>\n",
       "      <td>0.297767</td>\n",
       "      <td>0.293212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.294857</td>\n",
       "      <td>0.294756</td>\n",
       "      <td>0.294751</td>\n",
       "      <td>0.294509</td>\n",
       "      <td>0.009219</td>\n",
       "      <td>0.297748</td>\n",
       "      <td>0.577107</td>\n",
       "      <td>0.724275</td>\n",
       "      <td>0.300054</td>\n",
       "      <td>0.297748</td>\n",
       "      <td>0.293165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.294059</td>\n",
       "      <td>0.294120</td>\n",
       "      <td>0.293830</td>\n",
       "      <td>0.293136</td>\n",
       "      <td>0.011267</td>\n",
       "      <td>0.297697</td>\n",
       "      <td>0.565743</td>\n",
       "      <td>0.723974</td>\n",
       "      <td>0.300094</td>\n",
       "      <td>0.297697</td>\n",
       "      <td>0.293025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.293251</td>\n",
       "      <td>0.293293</td>\n",
       "      <td>0.293395</td>\n",
       "      <td>0.293560</td>\n",
       "      <td>0.008439</td>\n",
       "      <td>0.297580</td>\n",
       "      <td>0.555276</td>\n",
       "      <td>0.724200</td>\n",
       "      <td>0.299925</td>\n",
       "      <td>0.297580</td>\n",
       "      <td>0.292961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.293564</td>\n",
       "      <td>0.293232</td>\n",
       "      <td>0.293628</td>\n",
       "      <td>0.293620</td>\n",
       "      <td>0.005924</td>\n",
       "      <td>0.297523</td>\n",
       "      <td>0.545634</td>\n",
       "      <td>0.724358</td>\n",
       "      <td>0.299829</td>\n",
       "      <td>0.297523</td>\n",
       "      <td>0.292944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.293625</td>\n",
       "      <td>0.293686</td>\n",
       "      <td>0.293830</td>\n",
       "      <td>0.293762</td>\n",
       "      <td>0.014138</td>\n",
       "      <td>0.297469</td>\n",
       "      <td>0.536751</td>\n",
       "      <td>0.724736</td>\n",
       "      <td>0.299753</td>\n",
       "      <td>0.297469</td>\n",
       "      <td>0.292911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.293271</td>\n",
       "      <td>0.293444</td>\n",
       "      <td>0.293770</td>\n",
       "      <td>0.293600</td>\n",
       "      <td>0.008477</td>\n",
       "      <td>0.297443</td>\n",
       "      <td>0.528567</td>\n",
       "      <td>0.724510</td>\n",
       "      <td>0.299709</td>\n",
       "      <td>0.297443</td>\n",
       "      <td>0.292903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.293614</td>\n",
       "      <td>0.293444</td>\n",
       "      <td>0.291929</td>\n",
       "      <td>0.293186</td>\n",
       "      <td>0.016432</td>\n",
       "      <td>0.297422</td>\n",
       "      <td>0.521030</td>\n",
       "      <td>0.724070</td>\n",
       "      <td>0.299661</td>\n",
       "      <td>0.297422</td>\n",
       "      <td>0.292909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0.292504</td>\n",
       "      <td>0.292768</td>\n",
       "      <td>0.291716</td>\n",
       "      <td>0.291298</td>\n",
       "      <td>0.013128</td>\n",
       "      <td>0.297407</td>\n",
       "      <td>0.514093</td>\n",
       "      <td>0.723719</td>\n",
       "      <td>0.299606</td>\n",
       "      <td>0.297407</td>\n",
       "      <td>0.292933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0.292019</td>\n",
       "      <td>0.291618</td>\n",
       "      <td>0.290998</td>\n",
       "      <td>0.291449</td>\n",
       "      <td>0.014649</td>\n",
       "      <td>0.297297</td>\n",
       "      <td>0.507722</td>\n",
       "      <td>0.724111</td>\n",
       "      <td>0.299002</td>\n",
       "      <td>0.297297</td>\n",
       "      <td>0.293307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0.291463</td>\n",
       "      <td>0.291840</td>\n",
       "      <td>0.291201</td>\n",
       "      <td>0.291409</td>\n",
       "      <td>0.006351</td>\n",
       "      <td>0.297179</td>\n",
       "      <td>0.501869</td>\n",
       "      <td>0.723941</td>\n",
       "      <td>0.298547</td>\n",
       "      <td>0.297179</td>\n",
       "      <td>0.293520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>0.292140</td>\n",
       "      <td>0.292002</td>\n",
       "      <td>0.291635</td>\n",
       "      <td>0.292318</td>\n",
       "      <td>0.009698</td>\n",
       "      <td>0.297046</td>\n",
       "      <td>0.496492</td>\n",
       "      <td>0.724200</td>\n",
       "      <td>0.298137</td>\n",
       "      <td>0.297046</td>\n",
       "      <td>0.293659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>0.291534</td>\n",
       "      <td>0.291891</td>\n",
       "      <td>0.291716</td>\n",
       "      <td>0.291288</td>\n",
       "      <td>0.008832</td>\n",
       "      <td>0.296925</td>\n",
       "      <td>0.491545</td>\n",
       "      <td>0.723964</td>\n",
       "      <td>0.297964</td>\n",
       "      <td>0.296925</td>\n",
       "      <td>0.293591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>0.291837</td>\n",
       "      <td>0.292647</td>\n",
       "      <td>0.292030</td>\n",
       "      <td>0.292510</td>\n",
       "      <td>0.008917</td>\n",
       "      <td>0.296756</td>\n",
       "      <td>0.487001</td>\n",
       "      <td>0.724202</td>\n",
       "      <td>0.297615</td>\n",
       "      <td>0.296756</td>\n",
       "      <td>0.293601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566835</th>\n",
       "      <td>0.063613</td>\n",
       "      <td>0.063652</td>\n",
       "      <td>0.063882</td>\n",
       "      <td>0.063584</td>\n",
       "      <td>0.004849</td>\n",
       "      <td>0.064164</td>\n",
       "      <td>0.577966</td>\n",
       "      <td>0.008100</td>\n",
       "      <td>0.066310</td>\n",
       "      <td>0.064164</td>\n",
       "      <td>0.062667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566836</th>\n",
       "      <td>0.063694</td>\n",
       "      <td>0.063662</td>\n",
       "      <td>0.064064</td>\n",
       "      <td>0.063705</td>\n",
       "      <td>0.001260</td>\n",
       "      <td>0.064139</td>\n",
       "      <td>0.577977</td>\n",
       "      <td>0.008133</td>\n",
       "      <td>0.066238</td>\n",
       "      <td>0.064139</td>\n",
       "      <td>0.062687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566837</th>\n",
       "      <td>0.063683</td>\n",
       "      <td>0.063571</td>\n",
       "      <td>0.063872</td>\n",
       "      <td>0.063665</td>\n",
       "      <td>0.002988</td>\n",
       "      <td>0.064122</td>\n",
       "      <td>0.577987</td>\n",
       "      <td>0.008053</td>\n",
       "      <td>0.066207</td>\n",
       "      <td>0.064122</td>\n",
       "      <td>0.062684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566838</th>\n",
       "      <td>0.063593</td>\n",
       "      <td>0.063702</td>\n",
       "      <td>0.063963</td>\n",
       "      <td>0.063816</td>\n",
       "      <td>0.006391</td>\n",
       "      <td>0.064102</td>\n",
       "      <td>0.577998</td>\n",
       "      <td>0.008224</td>\n",
       "      <td>0.066173</td>\n",
       "      <td>0.064102</td>\n",
       "      <td>0.062677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566839</th>\n",
       "      <td>0.063754</td>\n",
       "      <td>0.063783</td>\n",
       "      <td>0.064125</td>\n",
       "      <td>0.063856</td>\n",
       "      <td>0.003540</td>\n",
       "      <td>0.064094</td>\n",
       "      <td>0.578008</td>\n",
       "      <td>0.008319</td>\n",
       "      <td>0.066164</td>\n",
       "      <td>0.064094</td>\n",
       "      <td>0.062671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566840</th>\n",
       "      <td>0.063885</td>\n",
       "      <td>0.064065</td>\n",
       "      <td>0.064195</td>\n",
       "      <td>0.064028</td>\n",
       "      <td>0.006088</td>\n",
       "      <td>0.064086</td>\n",
       "      <td>0.578017</td>\n",
       "      <td>0.008482</td>\n",
       "      <td>0.066160</td>\n",
       "      <td>0.064086</td>\n",
       "      <td>0.062658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566841</th>\n",
       "      <td>0.064128</td>\n",
       "      <td>0.064035</td>\n",
       "      <td>0.064438</td>\n",
       "      <td>0.064139</td>\n",
       "      <td>0.001998</td>\n",
       "      <td>0.064090</td>\n",
       "      <td>0.578024</td>\n",
       "      <td>0.008535</td>\n",
       "      <td>0.066160</td>\n",
       "      <td>0.064090</td>\n",
       "      <td>0.062667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566842</th>\n",
       "      <td>0.064077</td>\n",
       "      <td>0.064015</td>\n",
       "      <td>0.064337</td>\n",
       "      <td>0.064038</td>\n",
       "      <td>0.003293</td>\n",
       "      <td>0.064101</td>\n",
       "      <td>0.578028</td>\n",
       "      <td>0.008447</td>\n",
       "      <td>0.066154</td>\n",
       "      <td>0.064101</td>\n",
       "      <td>0.062695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566843</th>\n",
       "      <td>0.064118</td>\n",
       "      <td>0.064045</td>\n",
       "      <td>0.064418</td>\n",
       "      <td>0.064170</td>\n",
       "      <td>0.002904</td>\n",
       "      <td>0.064108</td>\n",
       "      <td>0.578030</td>\n",
       "      <td>0.008525</td>\n",
       "      <td>0.066155</td>\n",
       "      <td>0.064108</td>\n",
       "      <td>0.062707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566844</th>\n",
       "      <td>0.064138</td>\n",
       "      <td>0.064096</td>\n",
       "      <td>0.064489</td>\n",
       "      <td>0.064210</td>\n",
       "      <td>0.004057</td>\n",
       "      <td>0.064125</td>\n",
       "      <td>0.578031</td>\n",
       "      <td>0.008634</td>\n",
       "      <td>0.066157</td>\n",
       "      <td>0.064125</td>\n",
       "      <td>0.062739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566845</th>\n",
       "      <td>0.064229</td>\n",
       "      <td>0.064116</td>\n",
       "      <td>0.064499</td>\n",
       "      <td>0.064119</td>\n",
       "      <td>0.002228</td>\n",
       "      <td>0.064128</td>\n",
       "      <td>0.578029</td>\n",
       "      <td>0.008574</td>\n",
       "      <td>0.066151</td>\n",
       "      <td>0.064128</td>\n",
       "      <td>0.062750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566846</th>\n",
       "      <td>0.064138</td>\n",
       "      <td>0.064086</td>\n",
       "      <td>0.064509</td>\n",
       "      <td>0.064109</td>\n",
       "      <td>0.001170</td>\n",
       "      <td>0.064132</td>\n",
       "      <td>0.578026</td>\n",
       "      <td>0.008543</td>\n",
       "      <td>0.066149</td>\n",
       "      <td>0.064132</td>\n",
       "      <td>0.062760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566847</th>\n",
       "      <td>0.064128</td>\n",
       "      <td>0.064106</td>\n",
       "      <td>0.064509</td>\n",
       "      <td>0.064099</td>\n",
       "      <td>0.001703</td>\n",
       "      <td>0.064131</td>\n",
       "      <td>0.578023</td>\n",
       "      <td>0.008497</td>\n",
       "      <td>0.066149</td>\n",
       "      <td>0.064131</td>\n",
       "      <td>0.062759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566848</th>\n",
       "      <td>0.064128</td>\n",
       "      <td>0.063985</td>\n",
       "      <td>0.064418</td>\n",
       "      <td>0.064018</td>\n",
       "      <td>0.001735</td>\n",
       "      <td>0.064138</td>\n",
       "      <td>0.578020</td>\n",
       "      <td>0.008451</td>\n",
       "      <td>0.066150</td>\n",
       "      <td>0.064138</td>\n",
       "      <td>0.062772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566849</th>\n",
       "      <td>0.064027</td>\n",
       "      <td>0.063944</td>\n",
       "      <td>0.064377</td>\n",
       "      <td>0.063968</td>\n",
       "      <td>0.002064</td>\n",
       "      <td>0.064134</td>\n",
       "      <td>0.578017</td>\n",
       "      <td>0.008395</td>\n",
       "      <td>0.066151</td>\n",
       "      <td>0.064134</td>\n",
       "      <td>0.062762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566850</th>\n",
       "      <td>0.064077</td>\n",
       "      <td>0.063934</td>\n",
       "      <td>0.064216</td>\n",
       "      <td>0.063927</td>\n",
       "      <td>0.003113</td>\n",
       "      <td>0.064131</td>\n",
       "      <td>0.578014</td>\n",
       "      <td>0.008312</td>\n",
       "      <td>0.066150</td>\n",
       "      <td>0.064131</td>\n",
       "      <td>0.062757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566851</th>\n",
       "      <td>0.063946</td>\n",
       "      <td>0.063934</td>\n",
       "      <td>0.064226</td>\n",
       "      <td>0.064018</td>\n",
       "      <td>0.005957</td>\n",
       "      <td>0.064130</td>\n",
       "      <td>0.578013</td>\n",
       "      <td>0.008472</td>\n",
       "      <td>0.066150</td>\n",
       "      <td>0.064130</td>\n",
       "      <td>0.062757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566852</th>\n",
       "      <td>0.064077</td>\n",
       "      <td>0.064015</td>\n",
       "      <td>0.064347</td>\n",
       "      <td>0.064028</td>\n",
       "      <td>0.003146</td>\n",
       "      <td>0.064135</td>\n",
       "      <td>0.578012</td>\n",
       "      <td>0.008556</td>\n",
       "      <td>0.066152</td>\n",
       "      <td>0.064135</td>\n",
       "      <td>0.062763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566853</th>\n",
       "      <td>0.064128</td>\n",
       "      <td>0.063995</td>\n",
       "      <td>0.063760</td>\n",
       "      <td>0.063927</td>\n",
       "      <td>0.016743</td>\n",
       "      <td>0.064140</td>\n",
       "      <td>0.578011</td>\n",
       "      <td>0.008108</td>\n",
       "      <td>0.066156</td>\n",
       "      <td>0.064140</td>\n",
       "      <td>0.062770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566854</th>\n",
       "      <td>0.063986</td>\n",
       "      <td>0.063854</td>\n",
       "      <td>0.064155</td>\n",
       "      <td>0.063806</td>\n",
       "      <td>0.002357</td>\n",
       "      <td>0.064147</td>\n",
       "      <td>0.578010</td>\n",
       "      <td>0.008045</td>\n",
       "      <td>0.066169</td>\n",
       "      <td>0.064147</td>\n",
       "      <td>0.062770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566855</th>\n",
       "      <td>0.063825</td>\n",
       "      <td>0.063934</td>\n",
       "      <td>0.064125</td>\n",
       "      <td>0.063907</td>\n",
       "      <td>0.005201</td>\n",
       "      <td>0.064157</td>\n",
       "      <td>0.578011</td>\n",
       "      <td>0.008184</td>\n",
       "      <td>0.066208</td>\n",
       "      <td>0.064157</td>\n",
       "      <td>0.062752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566856</th>\n",
       "      <td>0.064017</td>\n",
       "      <td>0.063874</td>\n",
       "      <td>0.064084</td>\n",
       "      <td>0.063816</td>\n",
       "      <td>0.001554</td>\n",
       "      <td>0.064173</td>\n",
       "      <td>0.578013</td>\n",
       "      <td>0.008142</td>\n",
       "      <td>0.066271</td>\n",
       "      <td>0.064173</td>\n",
       "      <td>0.062722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566857</th>\n",
       "      <td>0.063774</td>\n",
       "      <td>0.063722</td>\n",
       "      <td>0.064114</td>\n",
       "      <td>0.063725</td>\n",
       "      <td>0.001930</td>\n",
       "      <td>0.064179</td>\n",
       "      <td>0.578015</td>\n",
       "      <td>0.008091</td>\n",
       "      <td>0.066294</td>\n",
       "      <td>0.064179</td>\n",
       "      <td>0.062711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566858</th>\n",
       "      <td>0.063754</td>\n",
       "      <td>0.063682</td>\n",
       "      <td>0.064135</td>\n",
       "      <td>0.063806</td>\n",
       "      <td>0.001247</td>\n",
       "      <td>0.064182</td>\n",
       "      <td>0.578019</td>\n",
       "      <td>0.008124</td>\n",
       "      <td>0.066310</td>\n",
       "      <td>0.064182</td>\n",
       "      <td>0.062701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566859</th>\n",
       "      <td>0.063825</td>\n",
       "      <td>0.063854</td>\n",
       "      <td>0.064195</td>\n",
       "      <td>0.063957</td>\n",
       "      <td>0.003121</td>\n",
       "      <td>0.064181</td>\n",
       "      <td>0.578023</td>\n",
       "      <td>0.008207</td>\n",
       "      <td>0.066308</td>\n",
       "      <td>0.064181</td>\n",
       "      <td>0.062702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566860</th>\n",
       "      <td>0.063916</td>\n",
       "      <td>0.063924</td>\n",
       "      <td>0.064307</td>\n",
       "      <td>0.064038</td>\n",
       "      <td>0.002764</td>\n",
       "      <td>0.064186</td>\n",
       "      <td>0.578027</td>\n",
       "      <td>0.008281</td>\n",
       "      <td>0.066320</td>\n",
       "      <td>0.064186</td>\n",
       "      <td>0.062701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566861</th>\n",
       "      <td>0.064057</td>\n",
       "      <td>0.063924</td>\n",
       "      <td>0.064388</td>\n",
       "      <td>0.063998</td>\n",
       "      <td>0.004898</td>\n",
       "      <td>0.064187</td>\n",
       "      <td>0.578029</td>\n",
       "      <td>0.008150</td>\n",
       "      <td>0.066320</td>\n",
       "      <td>0.064187</td>\n",
       "      <td>0.062701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566862</th>\n",
       "      <td>0.064017</td>\n",
       "      <td>0.063934</td>\n",
       "      <td>0.064317</td>\n",
       "      <td>0.063957</td>\n",
       "      <td>0.004241</td>\n",
       "      <td>0.064180</td>\n",
       "      <td>0.578031</td>\n",
       "      <td>0.008037</td>\n",
       "      <td>0.066322</td>\n",
       "      <td>0.064180</td>\n",
       "      <td>0.062685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566863</th>\n",
       "      <td>0.064077</td>\n",
       "      <td>0.063975</td>\n",
       "      <td>0.064317</td>\n",
       "      <td>0.063978</td>\n",
       "      <td>0.004918</td>\n",
       "      <td>0.064176</td>\n",
       "      <td>0.578032</td>\n",
       "      <td>0.008168</td>\n",
       "      <td>0.066319</td>\n",
       "      <td>0.064176</td>\n",
       "      <td>0.062680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566864</th>\n",
       "      <td>0.064098</td>\n",
       "      <td>0.064096</td>\n",
       "      <td>0.064337</td>\n",
       "      <td>0.064069</td>\n",
       "      <td>0.011441</td>\n",
       "      <td>0.064166</td>\n",
       "      <td>0.578032</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.066325</td>\n",
       "      <td>0.064166</td>\n",
       "      <td>0.062655</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>566841 rows  11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            open      high       low     close    volume     sma20      macd  \\\n",
       "24      0.294695  0.294816  0.295438  0.294691  0.007892  0.297465  1.000000   \n",
       "25      0.294988  0.294634  0.294983  0.294267  0.010340  0.297578  0.957259   \n",
       "26      0.294766  0.294846  0.293143  0.294024  0.016392  0.297686  0.917540   \n",
       "27      0.293887  0.293807  0.292859  0.293479  0.007877  0.297774  0.880663   \n",
       "28      0.293281  0.293565  0.293355  0.293479  0.010889  0.297817  0.846456   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "566860  0.063916  0.063924  0.064307  0.064038  0.002764  0.064186  0.578027   \n",
       "566861  0.064057  0.063924  0.064388  0.063998  0.004898  0.064187  0.578029   \n",
       "566862  0.064017  0.063934  0.064317  0.063957  0.004241  0.064180  0.578031   \n",
       "566863  0.064077  0.063975  0.064317  0.063978  0.004918  0.064176  0.578032   \n",
       "566864  0.064098  0.064096  0.064337  0.064069  0.011441  0.064166  0.578032   \n",
       "\n",
       "             obv  bb20_low  bb20_mid   bb20_up  \n",
       "24      0.724619  0.298127  0.297465  0.294494  \n",
       "25      0.724342  0.298357  0.297578  0.294490  \n",
       "26      0.723903  0.298665  0.297686  0.294401  \n",
       "27      0.723693  0.298952  0.297774  0.294294  \n",
       "28      0.723693  0.299108  0.297817  0.294225  \n",
       "...          ...       ...       ...       ...  \n",
       "566860  0.008281  0.066320  0.064186  0.062701  \n",
       "566861  0.008150  0.066320  0.064187  0.062701  \n",
       "566862  0.008037  0.066322  0.064180  0.062685  \n",
       "566863  0.008168  0.066319  0.064176  0.062680  \n",
       "566864  0.008475  0.066325  0.064166  0.062655  \n",
       "\n",
       "[566841 rows x 11 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "candles.apply(normalize_series, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "# Parameters\n",
    "params = {'batch_size': 64,\n",
    "          'shuffle': True,\n",
    "          'num_workers': 5}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _train(train_gen, model, optim, error_func):\n",
    "    losses = []\n",
    "    \n",
    "    for batch, labels in train_gen:\n",
    "        batch, labels = batch.cuda().float(), labels.cuda().float()\n",
    "        # set model to train mode\n",
    "        model.train()\n",
    "        \n",
    "        # clear gradients\n",
    "        model.zero_grad()\n",
    "        \n",
    "        output = model(batch)\n",
    "        loss = error_func(output, labels)\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        \n",
    "        \n",
    "        losses.append(loss)\n",
    "        \n",
    "    return round(float(sum(losses) / len(losses)), 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _valid(valid_gen, model, optim, error_func):\n",
    "    with torch.set_grad_enabled(False):\n",
    "        losses = []\n",
    "\n",
    "        for batch, labels in valid_gen:\n",
    "            batch, labels = batch.cuda().float(), labels.cuda().float()\n",
    "            \n",
    "            # set to eval mode\n",
    "            model.eval()\n",
    "            \n",
    "            # clear gradients\n",
    "            model.zero_grad()\n",
    "\n",
    "            output = model(batch)\n",
    "            loss = error_func(output, labels)\n",
    "\n",
    "            losses.append(loss)\n",
    "        \n",
    "    return round(float(sum(losses) / len(losses)), 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _test(test_gen, model, optim, error_func):\n",
    "    with torch.set_grad_enabled(False):\n",
    "        losses = []\n",
    "\n",
    "        for batch, labels in valid_gen:\n",
    "            batch, labels = batch.cuda().float(), labels.cuda().float()\n",
    "            \n",
    "            # set to eval mode\n",
    "            model.eval()\n",
    "            \n",
    "            # clear gradients\n",
    "            model.zero_grad()\n",
    "\n",
    "            output = model(batch)\n",
    "            loss = error_func(output, labels)\n",
    "\n",
    "            losses.append(loss)\n",
    "        \n",
    "    return round(float(sum(losses) / len(losses)), 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, model_name, optim, num_epochs, train_gen, valid_gen, test_gen=None):\n",
    "    \"\"\"Train a PyTorch model with optim as optimizer strategy\"\"\"\n",
    "    \n",
    "    for epoch_i in range(num_epochs):\n",
    "        \n",
    "        \n",
    "        def RMSE(x, y):\n",
    "            \n",
    "            # have to squish x into a rank 1 tensor with batch_size length with the outputs we want\n",
    "            if model_name == 'resnet':\n",
    "                 # torch.Size([64, 1])\n",
    "                x = x.squeeze(1)\n",
    "            elif model_name == 'gru':\n",
    "                # torch.Size([64, 30, 1])\n",
    "                x = x[:, 29, :] # take only the last prediction from the 30 time periods in our matrix\n",
    "                x = x.squeeze(1)\n",
    "            mse = torch.nn.MSELoss()\n",
    "            return torch.sqrt(mse(x, y))\n",
    "        \n",
    "        \n",
    "        # forward and backward passes of all batches inside train_gen\n",
    "        train_loss = _train(train_gen, model, optim, RMSE)\n",
    "        valid_loss = _valid(valid_gen, model, optim, RMSE)\n",
    "        \n",
    "        # run on test set if provided\n",
    "        if test_gen: test_output = _test(test_gen, model, optim)\n",
    "        else: test_output = \"no test selected\"\n",
    "        print(\"train loss: {}, valid loss: {}, test output: {}\".format(train_loss, valid_loss, test_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.CNN.CNN import CNN\n",
    "cnn = CNN().cuda().float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers.datasets import DFTimeSeriesDataset, ChartImageDataset\n",
    "from torch.utils.data import *\n",
    "# create dataloaders\n",
    "# specify the split between train_df and valid_df from the process of splitting dataset_windows \n",
    "split = 0.7\n",
    "\n",
    "s = int(len(candles_sliced) * 0.7)\n",
    "while s % params['batch_size'] != 0:\n",
    "    s += 1\n",
    "\n",
    "# create two ChartImageDatasets, split by split, for the purpose of creating a DataLoader for the specific model\n",
    "train_ds_cnn = ChartImageDataset(paths_to_images[:s], labels_candles_sliced[:s])\n",
    "valid_ds_cnn = ChartImageDataset(paths_to_images[s:], labels_candles_sliced[s:])\n",
    "train_gen_cnn = DataLoader(train_ds_cnn, **params)\n",
    "valid_gen_cnn = DataLoader(valid_ds_cnn, **params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(cnn, 'resnet', torch.optim.Adam(cnn.parameters(), 1e-3), 15, train_gen_cnn, valid_gen_cnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.GRU.GRU import GRUnet\n",
    "gru = GRUnet(num_features=12, num_rows=30, batch_size=64, hidden_size=500, num_layers=5).cuda().float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers.datasets import DFTimeSeriesDataset, ChartImageDataset\n",
    "from torch.utils.data import *\n",
    "# create dataloaders\n",
    "# specify the split between train_df and valid_df from the process of splitting dataset_windows \n",
    "split = 0.7\n",
    "\n",
    "s = int(len(candles_sliced) * 0.7)\n",
    "while s % params['batch_size'] != 0:\n",
    "    s += 1\n",
    "\n",
    "# create two ChartImageDatasets, split by split, for the purpose of creating a DataLoader for the specific model\n",
    "train_ds_gru = DFTimeSeriesDataset(candles_sliced[:s], labels_candles_sliced[:s])\n",
    "valid_ds_gru = DFTimeSeriesDataset(candles_sliced[s:], labels_candles_sliced[s:])\n",
    "train_gen_gru = DataLoader(train_ds_gru, **params, drop_last=True)\n",
    "valid_gen_gru = DataLoader(valid_ds_gru, **params, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.003663, valid loss: 0.001888, test output: no test selected\n",
      "train loss: 0.0021, valid loss: 0.002282, test output: no test selected\n",
      "train loss: 0.002023, valid loss: 0.001827, test output: no test selected\n",
      "train loss: 0.002007, valid loss: 0.001728, test output: no test selected\n",
      "train loss: 0.001978, valid loss: 0.001733, test output: no test selected\n"
     ]
    }
   ],
   "source": [
    "train(gru, 'gru', torch.optim.Adam(gru.parameters(), 1e-3), 5, train_gen_gru, valid_gen_gru)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers.saving_models import save_model, load_model\n",
    "\n",
    "save_model(gru, 'gru_weights')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "attempted relative import with no known parent package",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-53-72130cb4521b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mBackTest\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBackTest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Projects/FALKOR/BackTest.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mstrategies\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCNN_Strategy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mPortfolio\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPortfolio\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mhelpers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_processing\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: attempted relative import with no known parent package"
     ]
    }
   ],
   "source": [
    "from BackTest import BackTest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
